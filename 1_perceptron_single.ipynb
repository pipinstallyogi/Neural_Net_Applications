{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing keras and its libraries\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#wandb helps us looking and evaluating results\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/yogi15172853/uncategorized/runs/pii0ab6l\n",
      "Call `%%wandb` in the cell containing your training loop to display live results.\n"
     ]
    }
   ],
   "source": [
    "#logging code\n",
    "run = wandb.init()\n",
    "config = run.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data, X and y are common notation in ML where X stands for input and y stands for output\n",
    "#for example X_train is list of all the images or more precisely arrays, whereas y_train is list of all the labels corresponds to the images\n",
    "\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For simplicity we are just checking whetehr a give figure is 5 or not\n",
    "is_five_train = y_train ==5\n",
    "is_five_test = y_test == 5\n",
    "labels = ['Not Five', 'Is Five']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of image width and image height using the function shape\n",
    "# gives us the dimension which in our case is 60000 * 28 * 28\n",
    "# So, both height and widht comes to 28 in our case as the figure sizes are 28 * 28\n",
    "image_width = X_train.shape[1] \n",
    "image_height = X_test.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating_model\n",
    "#firstly we use sequential model from keras as this is the simplest one\n",
    "model = Sequential()\n",
    "\n",
    "#flatten is flattening our 2d array of 28 * 28 to one dimensional 784 length array \n",
    "#Input sizes in NN will always be same, if we deal with variable sizes padding has been done to make them equal\n",
    "model.add(Flatten(input_shape = (image_width,image_height)))\n",
    "          \n",
    "# adding single perceptron to the netwrok, where every input is connected to every output\n",
    "# Our network only output one single number that why there is a 1 inside the dense layer\n",
    "model.add(Dense(1, activation ='sigmoid')) #added sigmoid as activation function  \n",
    "          \n",
    "# gradient descent: to find the best weights by using computational methods.\n",
    "# backpropogation means changing the knobs to find the best weight  \n",
    "# mse is mean squared error which is square of the mean error. Loss is how much the result is deviated from the expected result          \n",
    "# an important factor in optimizer is learning rate\n",
    "model.compile(loss ='mse', optimizer ='adam', metrics = ['accuracy']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0907 - acc: 0.9093 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0908 - acc: 0.909 - 1s 16us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0903 - acc: 0.9097 - val_loss: 0.0892 - val_acc: 0.9108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f17830dc5f8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "model.fit(X_train, is_five_train, epochs = config.epochs, validation_data = (X_test, is_five_test), callbacks =[WandbCallback(labels=labels)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to debug = one way to to train more by increasing the epochs\n",
    "# second way is to train with a smaller set to check the data\n",
    "# we can check with the output of some little sample to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.7000 - acc: 0.3000 - val_loss: 0.6056 - val_acc: 0.3909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f178338aac8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(X_train[:20,:,:], is_five_train[:20], epochs = config.epochs, validation_data = (X_test, is_five_test), callbacks =[WandbCallback(labels=labels)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000000e+00]\n",
      " [0.000000e+00]\n",
      " [1.000000e+00]\n",
      " [1.000000e+00]\n",
      " [0.000000e+00]\n",
      " [1.000000e+00]\n",
      " [0.000000e+00]\n",
      " [3.156066e-05]\n",
      " [0.000000e+00]\n",
      " [0.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#will show us the first ten predictions from the test dataset\n",
    "print (model.predict(X_test[:10,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid function: big negatives will be turned to 0 and big positives will beturned to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
